# Instalaci√≥n e importaci√≥n de librer√≠as
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Configuraci√≥n
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 8)

# ============================================================================
# 1. CARGAR Y PREPARAR DATOS
# ============================================================================
print("="*60)
print("1. CARGANDO DATASET IRIS")
print("="*60)

# Cargar dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target

print(f"Muestras: {X.shape[0]} | Caracter√≠sticas: {X.shape[1]} | Clases: {len(np.unique(y))}")

# Normalizar datos
scaler = StandardScaler()
X = scaler.fit_transform(X)
print("‚úì Datos normalizados")

# ============================================================================
# 2. DEFINIR MODELOS
# ============================================================================
modelos = {
    '1NN': KNeighborsClassifier(n_neighbors=1),
    '3NN': KNeighborsClassifier(n_neighbors=3),
    '5NN': KNeighborsClassifier(n_neighbors=5),
    '7NN': KNeighborsClassifier(n_neighbors=7),
    '9NN': KNeighborsClassifier(n_neighbors=9),
    'Naive Bayes': GaussianNB()
}

# ============================================================================
# 3. EVALUAR MODELOS
# ============================================================================
resultados = []

# --- HOLD-OUT 70/30 ---
print("\n" + "="*60)
print("2. HOLD-OUT 70/30")
print("="*60)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

for nombre, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    resultados.append([nombre, 'Hold-Out 70/30', acc, 0])
    print(f"{nombre:15s} Accuracy: {acc:.4f}")

# --- 10-FOLD CROSS-VALIDATION ---
print("\n" + "="*60)
print("3. 10-FOLD CROSS-VALIDATION")
print("="*60)

for nombre, modelo in modelos.items():
    scores = cross_val_score(modelo, X, y, cv=10)
    media = scores.mean()
    std = scores.std()
    resultados.append([nombre, '10-Fold CV', media, std])
    print(f"{nombre:15s} Accuracy: {media:.4f} (+/- {std:.4f})")

# --- LEAVE-ONE-OUT ---
print("\n" + "="*60)
print("4. LEAVE-ONE-OUT")
print("="*60)

loo = LeaveOneOut()
for nombre, modelo in modelos.items():
    scores = cross_val_score(modelo, X, y, cv=loo)
    acc = scores.mean()
    resultados.append([nombre, 'Leave-One-Out', acc, 0])
    print(f"{nombre:15s} Accuracy: {acc:.4f}")

# ============================================================================
# 4. TABLA DE RESULTADOS
# ============================================================================
print("\n" + "="*60)
print("5. RESUMEN DE RESULTADOS")
print("="*60)

df_resultados = pd.DataFrame(resultados, columns=['Modelo', 'Validaci√≥n', 'Accuracy', 'Std'])

# Tabla pivote
tabla = df_resultados.pivot_table(index='Modelo', columns='Validaci√≥n', values='Accuracy')
tabla = tabla[['Hold-Out 70/30', '10-Fold CV', 'Leave-One-Out']]

print("\n" + tabla.to_string())

# Mejor modelo
print(f"\nüìä MEJOR MODELO PROMEDIO: {df_resultados.groupby('Modelo')['Accuracy'].mean().idxmax()}")
print(f"   Accuracy promedio: {df_resultados.groupby('Modelo')['Accuracy'].mean().max():.4f}")

# ============================================================================
# 5. VISUALIZACIONES
# ============================================================================
print("\n" + "="*60)
print("6. GENERANDO GR√ÅFICAS")
print("="*60)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Gr√°fica 1: Comparaci√≥n por m√©todo
ax1 = axes[0, 0]
tabla.plot(kind='bar', ax=ax1, width=0.8)
ax1.set_title('Comparaci√≥n de Accuracy por M√©todo', fontweight='bold')
ax1.set_ylabel('Accuracy')
ax1.set_ylim([0.85, 1.0])
ax1.legend(loc='lower right', fontsize=8)
ax1.grid(axis='y', alpha=0.3)
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')

# Gr√°fica 2: Heatmap
ax2 = axes[0, 1]
sns.heatmap(tabla, annot=True, fmt='.3f', cmap='YlGnBu', ax=ax2, cbar_kws={'label': 'Accuracy'})
ax2.set_title('Heatmap de Accuracies', fontweight='bold')
plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')

# Gr√°fica 3: Efecto de K en KNN
ax3 = axes[1, 0]
knn_data = df_resultados[df_resultados['Modelo'] != 'Naive Bayes']
for metodo in ['Hold-Out 70/30', '10-Fold CV', 'Leave-One-Out']:
    datos = knn_data[knn_data['Validaci√≥n'] == metodo]
    k_vals = [1, 3, 5, 7, 9]
    accs = [datos[datos['Modelo'] == f'{k}NN']['Accuracy'].values[0] for k in k_vals]
    ax3.plot(k_vals, accs, marker='o', label=metodo, linewidth=2)
ax3.set_title('Efecto de K en KNN', fontweight='bold')
ax3.set_xlabel('Valor de K')
ax3.set_ylabel('Accuracy')
ax3.legend(fontsize=8)
ax3.grid(True, alpha=0.3)
ax3.set_xticks([1, 3, 5, 7, 9])

# Gr√°fica 4: Matriz de confusi√≥n (5NN)
ax4 = axes[1, 1]
modelo_5nn = KNeighborsClassifier(n_neighbors=5)
modelo_5nn.fit(X_train, y_train)
y_pred = modelo_5nn.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4)
ax4.set_title('Matriz de Confusi√≥n (5NN - Hold-Out)', fontweight='bold')
ax4.set_xlabel('Predicci√≥n')
ax4.set_ylabel('Real')

plt.tight_layout()
plt.show()

print("‚úì Visualizaciones completadas")

# ============================================================================
# 6. REPORTE DETALLADO (OPCIONAL)
# ============================================================================
print("\n" + "="*60)
print("7. REPORTE DETALLADO (5NN con Hold-Out)")
print("="*60)
print(classification_report(y_test, y_pred, target_names=iris.target_names))

print("\n" + "="*60)
print("‚úì AN√ÅLISIS COMPLETADO")
print("="*60)
